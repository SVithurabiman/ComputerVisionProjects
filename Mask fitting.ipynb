{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "!git clone https://github.com/spmallick/learnopencv.git\r\n",
                "%cd learnopencv/FaceMaskOverlay/\r\n",
                "!pip install -r requirements.txt"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "!python overlay_with_mask.py --cfg experiments/300w/face_alignment_300w_hrnet_w18.yaml --landmark_model HR18-300W.pth --mask_image masks/3m.png"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import argparse\r\n",
                "import csv\r\n",
                "import os\r\n",
                "import pprint\r\n",
                "from collections import OrderedDict\r\n",
                "import pandas as pd\r\n",
                "import cv2\r\n",
                "import numpy as np\r\n",
                "import torch\r\n",
                "\r\n",
                "import lib.models as models\r\n",
                "from lib.config import (\r\n",
                "    config,\r\n",
                "    update_config,\r\n",
                ")\r\n",
                "from lib.core.evaluation import decode_preds\r\n",
                "from lib.utils import utils\r\n",
                "from lib.utils.transforms import crop\r\n",
                "\r\n",
                "from skimage import transform\r\n",
                "from skimage.io import imread, imshow\r\n",
                "from skimage.transform import rescale, resize\r\n",
                "\r\n",
                "import os\r\n",
                "\r\n",
                "def parse_args():\r\n",
                "\r\n",
                "    parser = argparse.ArgumentParser(description=\"Face Mask Overlay\")\r\n",
                "\r\n",
                "    parser.add_argument(\r\n",
                "        \"--cfg\", help=\"experiment configuration filename\", required=True, type=str,\r\n",
                "    )\r\n",
                "    parser.add_argument(\r\n",
                "        \"--landmark_model\",\r\n",
                "        help=\"path to model for landmarks exctraction\",\r\n",
                "        required=True,\r\n",
                "        type=str,\r\n",
                "    )\r\n",
                "    parser.add_argument(\r\n",
                "        \"--detector_model\",\r\n",
                "        help=\"path to detector model\",\r\n",
                "        type=str,\r\n",
                "        default=\"detection/face_detector.prototxt\",\r\n",
                "    )\r\n",
                "    parser.add_argument(\r\n",
                "        \"--detector_weights\",\r\n",
                "        help=\"path to detector weights\",\r\n",
                "        type=str,\r\n",
                "        default=\"detection/face_detector.caffemodel\",\r\n",
                "    )\r\n",
                "    parser.add_argument(\r\n",
                "        \"--mask_image\", help=\"path to a .png file with a mask\", required=True, type=str,\r\n",
                "    )\r\n",
                "    parser.add_argument(\"--device\", default=\"cpu\", help=\"Device to inference on\")\r\n",
                "\r\n",
                "    args = parser.parse_args()\r\n",
                "    update_config(config, args)\r\n",
                "    return args\r\n",
                "\r\n",
                "\r\n",
                "def main():\r\n",
                "    \r\n",
                "  # parsing script arguments\r\n",
                "      args = parse_args()\r\n",
                "      device = torch.device(args.device)\r\n",
                "\r\n",
                "      # initialize logger\r\n",
                "      logger, final_output_dir, tb_log_dir = utils.create_logger(config, args.cfg, \"demo\")\r\n",
                "\r\n",
                "      # log arguments and config values\r\n",
                "      logger.info(pprint.pformat(args))\r\n",
                "      logger.info(pprint.pformat(config))\r\n",
                "\r\n",
                "      # init landmark model\r\n",
                "      model = models.get_face_alignment_net(config)\r\n",
                "\r\n",
                "      # get input size from the config\r\n",
                "      input_size = config.MODEL.IMAGE_SIZE\r\n",
                "\r\n",
                "      # load model\r\n",
                "      state_dict = torch.load(args.landmark_model, map_location=device)\r\n",
                "\r\n",
                "      # remove `module.` prefix from the pre-trained weights\r\n",
                "      new_state_dict = OrderedDict()\r\n",
                "      for key, value in state_dict.items():\r\n",
                "          name = key[7:]\r\n",
                "          new_state_dict[name] = value\r\n",
                "\r\n",
                "      # load weights without the prefix\r\n",
                "      model.load_state_dict(new_state_dict)\r\n",
                "      # run model on device\r\n",
                "      model = model.to(device)\r\n",
                "\r\n",
                "      # init mean and std values for the landmark model's input\r\n",
                "      mean = config.MODEL.MEAN\r\n",
                "      mean = np.array(mean, dtype=np.float32)\r\n",
                "      std = config.MODEL.STD\r\n",
                "      std = np.array(std, dtype=np.float32)\r\n",
                "\r\n",
                "      # defining prototxt and caffemodel paths\r\n",
                "      detector_model = args.detector_model\r\n",
                "      detector_weights = args.detector_weights\r\n",
                "\r\n",
                "      # load model\r\n",
                "      detector = cv2.dnn.readNetFromCaffe(detector_model, detector_weights)\r\n",
                " \r\n",
                "      lm_c=0\r\n",
                "      f_c=0\r\n",
                "      frame_num = 0\r\n",
                "      folder=\"/content/gdrive/MyDrive/IterateAI/Age_gender_detection/dataset/imdb_pre_processed1/\"   #Input Folder\r\n",
                "      out=\"/content/gdrive/MyDrive/Output_imdb1/\" #Output folder\r\n",
                "      #csv_=pd.read_csv(\"/content/gdrive/MyDrive/remaining_wiki.csv\")\r\n",
                "      df=pd.DataFrame()\r\n",
                "\r\n",
                "      for subfolder in os.listdir(folder):\r\n",
                "        print(subfolder)\r\n",
                "  \r\n",
                "        temp_out=os.path.join(out,subfolder)\r\n",
                "        os.mkdir(temp_out)\r\n",
                "        temp_out+='/'\r\n",
                "        t_subfolder=os.path.join(folder,subfolder)\r\n",
                "        t_subfolder+='/'\r\n",
                "\r\n",
                "    \r\n",
                "        xx=0\r\n",
                "        for new in os.listdir(t_subfolder):\r\n",
                "\r\n",
                "          try:\r\n",
                "            maskedd=0\r\n",
                "            fl=1 #flag to limit face detection to 1\r\n",
                "            pa=os.path.join(t_subfolder,new)\r\n",
                "            print(pa)\r\n",
                "     \r\n",
                "            frame=cv2.imread(pa)\r\n",
                "            # break if no frame\r\n",
                "      \r\n",
                "  \r\n",
                "            landmarks_img = frame.copy()\r\n",
                "            result = frame.copy()\r\n",
                "            result = result.astype(np.float32) / 255.0\r\n",
                "\r\n",
                "            # get frame's height and width\r\n",
                "            height, width = frame.shape[:2]  # 640x480\r\n",
                "\r\n",
                "            # resize and subtract BGR mean values, since Caffe uses BGR images for input\r\n",
                "            blob = cv2.dnn.blobFromImage(\r\n",
                "                frame, scalefactor=1.0, size=(300, 300), mean=(104.0, 177.0, 123.0),\r\n",
                "            )\r\n",
                "            # passing blob through the network to detect faces\r\n",
                "            detector.setInput(blob)\r\n",
                "            # detector output format:\r\n",
                "            # [image_id, class, confidence, left, bottom, right, top]\r\n",
                "            face_detections = detector.forward()\r\n",
                "            \r\n",
                "            # loop over the detections\r\n",
                "            for i in range(0, face_detections.shape[2]):\r\n",
                "                # extract confidence\r\n",
                "\r\n",
                "                confidence = face_detections[0, 0, i, 2]\r\n",
                "\r\n",
                "                # filter detections by confidence greater than the minimum threshold\r\n",
                "                if (confidence > 0.6) and (fl==1):\r\n",
                "                    fl=0\r\n",
                "                    # get coordinates of the bounding box\r\n",
                "                    box = face_detections[0, 0, i, 3:7] * np.array(\r\n",
                "                        [width, height, width, height],\r\n",
                "                    )\r\n",
                "                    (x1, y1, x2, y2) = box.astype(\"int\")\r\n",
                "\r\n",
                "            # waiting for the escape button to exit\r\n",
                "\r\n",
                "\r\n",
                "                    # crop to detection and resize\r\n",
                "                    resized = crop(\r\n",
                "                        frame,\r\n",
                "                        torch.Tensor([x1 + (x2 - x1) / 2, y1 + (y2 - y1) / 2]),\r\n",
                "                        1.5,\r\n",
                "                        tuple(input_size),\r\n",
                "                    )\r\n",
                "\r\n",
                "                    img = resized.astype(np.float32) / 255.0\r\n",
                "                    # normalize landmark net input\r\n",
                "                    \r\n",
                "                    normalized_img = (img - mean) / std\r\n",
                "\r\n",
                "                    # predict face landmarks\r\n",
                "                    model = model.eval()\r\n",
                "                    with torch.no_grad():\r\n",
                "                        input = torch.Tensor(normalized_img.transpose([2, 0, 1]))\r\n",
                "                        input = input.to(device)\r\n",
                "                        output = model(input.unsqueeze(0))\r\n",
                "                        score_map = output.data.cpu()\r\n",
                "                        preds = decode_preds(\r\n",
                "                            score_map,\r\n",
                "                            [torch.Tensor([x1 + (x2 - x1) / 2, y1 + (y2 - y1) / 2])],\r\n",
                "                            [1.5],\r\n",
                "                            score_map.shape[2:4],\r\n",
                "                        )\r\n",
                "\r\n",
                "                        preds = preds.squeeze(0)\r\n",
                "                        landmarks = preds.data.cpu().detach().numpy()\r\n",
                "                        # draw landmarks\r\n",
                "                        #print(landmarks)\r\n",
                "                        for k, landmark in enumerate(landmarks[0:17], 1):\r\n",
                "                            landmarks_img = cv2.circle(\r\n",
                "                                landmarks_img,\r\n",
                "                                center=(landmark[0], landmark[1]),\r\n",
                "                                radius=3,\r\n",
                "                                color=(0, 0, 255),\r\n",
                "                                thickness=-1,\r\n",
                "                            )\r\n",
                "                            # draw landmarks' labels\r\n",
                "                            landmarks_img = cv2.putText(\r\n",
                "                                img=landmarks_img,\r\n",
                "                                text=str(k),\r\n",
                "                                org=(int(landmark[0]) + 5, int(landmark[1]) + 5),\r\n",
                "                                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\r\n",
                "                                fontScale=0.5,\r\n",
                "                                color=(0, 255, 0),\r\n",
                "                            )\r\n",
                "                        k=29\r\n",
                "                        landmark=landmarks[29]\r\n",
                "                        landmarks_img = cv2.circle(\r\n",
                "                              landmarks_img,\r\n",
                "                              center=(landmark[0], landmark[1]),\r\n",
                "                              radius=3,\r\n",
                "                              color=(0, 0, 255),\r\n",
                "                              thickness=-1,\r\n",
                "                          )\r\n",
                "                        # draw landmarks' labels\r\n",
                "                        landmarks_img = cv2.putText(\r\n",
                "                            img=landmarks_img,\r\n",
                "                            text=str(k),\r\n",
                "                            org=(int(landmark[0]) + 5, int(landmark[1]) + 5),\r\n",
                "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\r\n",
                "                            fontScale=0.5,\r\n",
                "                            color=(0, 255, 0),\r\n",
                "                        )\r\n",
                "\r\n",
                "              \r\n",
                "                    lm_c+=1\r\n",
                "                    # get chosen landmarks 2-16, 30 as destination points\r\n",
                "                    # note that landmarks numbering starts from 0\r\n",
                "                    if True:\r\n",
                "                      dst_pts = np.array(\r\n",
                "                          [\r\n",
                "                              landmarks[1],\r\n",
                "                              landmarks[2],\r\n",
                "                              landmarks[3],\r\n",
                "                              landmarks[4],\r\n",
                "                              landmarks[5],\r\n",
                "                              landmarks[6],\r\n",
                "                              landmarks[7],\r\n",
                "                              landmarks[8],\r\n",
                "                              landmarks[9],\r\n",
                "                              landmarks[10],\r\n",
                "                              landmarks[11],\r\n",
                "                              landmarks[12],\r\n",
                "                              landmarks[13],\r\n",
                "                              landmarks[14],\r\n",
                "                              landmarks[15],\r\n",
                "                              landmarks[29],\r\n",
                "                          ],\r\n",
                "                          dtype=\"float32\",\r\n",
                "                      )\r\n",
                "                      #Calculatig Eculedian Distance betweeb Landmarks\r\n",
                "                      d = np.diff(dst_pts[:-2], axis=0) \r\n",
                "                      se = np.hypot(d[:,0], d[:,1])\r\n",
                "\r\n",
                "\r\n",
                "                      #set threshold   \r\n",
                "                      c=np.count_nonzero(se>54.5)   #total face                \r\n",
                "                      c1=np.count_nonzero(se[:6]>44) #left side\r\n",
                "                      c5=np.count_nonzero(se[12:17]>44) #right side\r\n",
                "\r\n",
                "                      c4=landmarks[29][1]-landmarks[23][1] #nose point below the head point\r\n",
                "\r\n",
                "                      if c==0 and (c1==0) and (c5==0) and (c4>0):\r\n",
                "                        #print(\"cant put mask\")\r\n",
                "                        f_c+=1\r\n",
                "              \r\n",
                "                        # load mask annotations from csv file to source points\r\n",
                "                        mask_annotation = os.path.splitext(os.path.basename(args.mask_image))[0]\r\n",
                "                        mask_annotation = os.path.join(\r\n",
                "                            os.path.dirname(args.mask_image), mask_annotation + \".csv\",\r\n",
                "                        )\r\n",
                "\r\n",
                "                        with open(mask_annotation) as csv_file:\r\n",
                "                            csv_reader = csv.reader(csv_file, delimiter=\",\")\r\n",
                "                            src_pts = []\r\n",
                "                            for i, row in enumerate(csv_reader):\r\n",
                "                                # skip head or empty line if it's there\r\n",
                "                                try:\r\n",
                "                                    src_pts.append(np.array([float(row[1]), float(row[2])]))\r\n",
                "                                except ValueError:\r\n",
                "                                    continue\r\n",
                "                        src_pts = np.array(src_pts, dtype=\"float32\")\r\n",
                "                        # overlay with a mask only if all landmarks have positive coordinates:\r\n",
                "                        if (landmarks > 0).all():\r\n",
                "                            # load mask image\r\n",
                "                            mask_img = cv2.imread(args.mask_image, cv2.IMREAD_UNCHANGED)\r\n",
                "                            mask_img = mask_img.astype(np.float32)\r\n",
                "                            mask_img = mask_img / 255.0\r\n",
                "                   \r\n",
                "                            tform = transform.estimate_transform('projective', src_pts, dst_pts)\r\n",
                "                            transformed_mask = transform.warp(mask_img, tform.inverse)\r\n",
                "                           \r\n",
                "                            transformed_mask=transformed_mask[0:result.shape[0],0:result.shape[1]]\r\n",
                "                 \r\n",
                "      \r\n",
                "                            # mask overlay\r\n",
                "                            alpha_mask = transformed_mask[:, :, 3]\r\n",
                "                            alpha_image = 1.0 - alpha_mask\r\n",
                "                            \r\n",
                "                          \r\n",
                "                          \r\n",
                "                            for c in range(0, 3):\r\n",
                "                                result[:, :, c] = (\r\n",
                "                                    alpha_mask * transformed_mask[:, :, c]\r\n",
                "                                    + alpha_image * result[:, :, c]\r\n",
                "                                )\r\n",
                "                            #fol=\"/content/Output/\"\r\n",
                "                            name=os.path.join(temp_out,new)\r\n",
                "                          \r\n",
                "                            #name= \"./content/Output/\"+str(new)+\".jpg\"\r\n",
                "                            cv2.imwrite(name, 255*result)\r\n",
                "                            maskedd=1\r\n",
                "            #csv generation                 \r\n",
                "            to_append=[pa, maskedd]\r\n",
                "            a_series = pd. Series(to_append)\r\n",
                "            df = df. append(a_series, ignore_index=True)\r\n",
                "            #df=pd.concat([csvout,df],axis=0,ignore_index=True)\r\n",
                "            df.to_csv(\"/content/gdrive/MyDrive/imdbpreproc1_csv1.csv\") #csv Path\r\n",
                "                          \r\n",
                "          except:\r\n",
                "            print(\"errorrr.............................\")\r\n",
                "            continue\r\n",
                "\r\n",
                "\r\n",
                "      print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\r\n",
                "      print(lm_c,f_c)\r\n",
                "        \r\n",
                "\r\n",
                "if __name__ == \"__main__\":\r\n",
                "\r\n",
                "  main()\r\n",
                "\r\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}