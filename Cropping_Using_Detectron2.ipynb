{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cropping Using Detectron2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PC8j8X8UJqs"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "# This is the current pytorch version on Colab. Uncomment this if Colab changes its pytorch version\n",
        "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-iAkyOiUMuc",
        "outputId": "94359296-2f45-4e9a-bbed-a98623b9f63b"
      },
      "source": [
        "# check pytorch installation: \n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.9\")   # please manually install torch 1.9 if Colab changes its default version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9UxTECLUM2O"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHEr46dfUNO8",
        "outputId": "df4d7689-61b8-4817-cb04-5a906106cc6b"
      },
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f10217.pkl: 178MB [00:06, 25.8MB/s]                           \n",
            "The checkpoint state_dict contains keys that are not used by the model:\n",
            "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdHqTfQDUNRZ",
        "outputId": "30d04b5f-714f-469f-ad31-8a7574a80edf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exLV-evmUfE6"
      },
      "source": [
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCBqtfJoUpIj"
      },
      "source": [
        "def crop(img, box):\n",
        "  x0=int(box[0])\n",
        "  y0=int(box[1])\n",
        "  x1=int(box[2])\n",
        "  y1=int(box[3])\n",
        "  #print(x0,y0,x1,y1)\n",
        "  crop_img = img[y0:y1, x0:x1]\n",
        "  return crop_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzLQqWT9UrAe"
      },
      "source": [
        " folder='/foldername'\n",
        " #folder_list=os.listdir(folder)\n",
        " results_folder='/cfoldername'\n",
        "\n",
        " #folder_list=pd.read_csv(\"/csvname\")\n",
        " counter=18993\n",
        " for file in folder_list[\"0\"][18993:]:\n",
        "  print(counter)\n",
        "  counter+=1\n",
        "  path=os.path.join(folder,file)\n",
        "  print(path)\n",
        "  im = cv2.imread(path)\n",
        "  outputs = predictor(im)\n",
        "  temp_count=0\n",
        "  mask_array = outputs['instances'].pred_masks.to(\"cpu\").numpy()\n",
        "  num_instances = mask_array.shape[0]\n",
        "  scores = outputs['instances'].scores.to(\"cpu\").numpy()\n",
        "  labels = outputs['instances'].pred_classes .to(\"cpu\").numpy()\n",
        "  bbox   = outputs['instances'].pred_boxes.to(\"cpu\").tensor.numpy()\n",
        "  human=np.where(labels==0)[0].tolist() # extracting only humans\n",
        "  mask_array = np.moveaxis(mask_array, 0, -1)\n",
        "  mask_array_instance = []\n",
        "\n",
        "  for i in range(1): # getting only the firss >> depend on the data set\n",
        "      temp_img=np.copy(im)\n",
        "      img = np.zeros_like(im)\n",
        "      mask_array_instance.append(mask_array[:, :, i:(i+1)])\n",
        "      if i in human:\n",
        "        temp_img= np.where(mask_array_instance[i] == False, 255, temp_img)\n",
        "        res_img=crop(temp_img,bbox[i])\n",
        "        result_name=file\n",
        "        result=os.path.join(results_folder,result_name)\n",
        "        cv2.imwrite(result,res_img)\n",
        "        #cv2_imshow(temp_img)\n",
        "        #cv2_imshow(res_img)\n",
        "        temp_count+=1\n",
        "      else:\n",
        "        continue\n",
        "      \n",
        "  #img_mask = np.asarray(img_mask)\n",
        "  #output = cv2.addWeighted(im, 0.7, img_mask, 0.3, 0) #blending 2 images"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}